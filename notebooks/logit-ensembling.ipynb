{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92958ca7",
   "metadata": {},
   "source": [
    "This notebook shows how to perform logit ensembled predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3731ba28",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a662cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\r\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f40c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df0d329",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a535492d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset emotion (/home/ec2-user/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f60c37aa28d471cacd3c9db9613cd35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "emotions = load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c310f544",
   "metadata": {},
   "source": [
    "## Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e43bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13037cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-19f1f721714bd971.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb1d0c4ad124016905ea16c24addff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-11b6ba8196e5b164.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "\n",
    "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)\n",
    "emotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c9f23",
   "metadata": {},
   "source": [
    "## Metric computation utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb053c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_accuracy(models):\n",
    "    def fn(batch):\n",
    "        inputs = {\n",
    "            k: v.to(device)\n",
    "            for k, v in batch.items()\n",
    "            if k in tokenizer.model_input_names\n",
    "        }\n",
    "        outputs = []\n",
    "        # Ensembling.\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                outputs.append(model(**inputs).logits)\n",
    "        outputs = torch.stack(outputs, 0)\n",
    "        output = torch.sum(outputs, 0)\n",
    "        pred_label = torch.argmax(output, axis=-1)\n",
    "        return {\"predicted_label\": pred_label.cpu().numpy()}\n",
    "\n",
    "    return fn\n",
    "\n",
    "\n",
    "def compute_test_accuracy(models, split=\"validation\"):\n",
    "    accuracy_fn = get_test_accuracy(models)\n",
    "\n",
    "    new_dataset = emotions_encoded[split].map(accuracy_fn, batched=True, batch_size=128)\n",
    "    new_dataset.set_format(\"pandas\")\n",
    "\n",
    "    cols = [\"label\", \"predicted_label\"]\n",
    "    df = new_dataset[:][cols]\n",
    "    return sum(df[\"label\"] == df[\"predicted_label\"]) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac594c0",
   "metadata": {},
   "source": [
    "## Perform ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "286f6932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: sayakpaul/distilbert-base-uncased-finetuned-emotion-lr-3e-05-wd-001.\n",
      "Checkpoint loaded.\n",
      "Loading checkpoint: sayakpaul/distilbert-base-uncased-finetuned-emotion-lr-2e-05-wd-0001.\n",
      "Checkpoint loaded.\n",
      "Loading checkpoint: sayakpaul/distilbert-base-uncased-finetuned-emotion-lr-0.0006-wd-0003.\n",
      "Checkpoint loaded.\n",
      "Loading checkpoint: sayakpaul/distilbert-base-uncased-finetuned-emotion-lr-1e-05-wd-0002.\n",
      "Checkpoint loaded.\n",
      "Loading checkpoint: sayakpaul/distilbert-base-uncased-finetuned-emotion-lr-0.0003-wd-003.\n",
      "Checkpoint loaded.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "models = []\n",
    "\n",
    "lrs = [3e-5, 2e-5, 6e-4, 1e-5, 3e-4]\n",
    "wds = [1e-2, 1e-3, 3e-3, 2e-3, 3e-2]\n",
    "\n",
    "for lr, wd in zip(lrs, wds):\n",
    "    model_name = f\"{model_ckpt}-finetuned-emotion-lr-{lr}-wd-{str(wd).replace('.', '')}\"\n",
    "    model_id = f\"sayakpaul/{model_name}\"\n",
    "    print(f\"Loading checkpoint: {model_id}.\")\n",
    "    models.append(\n",
    "        AutoModelForSequenceClassification.from_pretrained(model_id).to(device)\n",
    "    )\n",
    "    print(\"Checkpoint loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1206d70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128872d5e46941778c24e662face7c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f330bb004474651ad8b153556a84651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b447b3967804269ba322bdb4a238daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bc323aff1046fbafe8a56e3bb1d3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d146fee156a43b8a4da333b773f84b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.919, 2: 0.914, 3: 0.9195, 4: 0.917, 5: 0.935}\n"
     ]
    }
   ],
   "source": [
    "ensemble_scores = {}\n",
    "\n",
    "for num_members in range(1, len(models) + 1):\n",
    "    accuracy = compute_test_accuracy(models[:num_members], \"validation\")\n",
    "    ensemble_scores.update({num_members: accuracy})\n",
    "\n",
    "print(ensemble_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
